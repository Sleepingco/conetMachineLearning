

import streamlit as st
from huggingface_hub import InferenceClient
from PIL import Image
import requests

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ì´ë¯¸ì§€ ë¶„ë¥˜ with Hugging Face", layout="centered")
st.title("ğŸ§  Hugging Face ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°")

# --- Hugging Face API ì„¤ì • ---
API_TOKEN = ""
client = InferenceClient(token=API_TOKEN)

# --- ì´ë¯¸ì§€ ì—…ë¡œë“œ ---
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])

if uploaded_file:
    st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
    image_bytes = uploaded_file.read()

    with st.spinner("ë¶„ë¥˜ ì¤‘ì…ë‹ˆë‹¤..."):
        try:    
            # --- ì´ë¯¸ì§€ ë¶„ë¥˜ ìš”ì²­ ---
            results = client.image_classification(
                image_bytes,
                model="google/vit-base-patch16-224"
            )

            st.success("âœ… ë¶„ë¥˜ ì™„ë£Œ!")
            st.write(results)

            # ê°€ì¥ ë†’ì€ í™•ë¥  ë¼ë²¨ 1ê°œ ì¶”ì¶œ (ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´)
            main_label = results[0]["label"].split(",")[0].strip()

            # ìƒìœ„ ë¼ë²¨ ì´ë¦„ ì¶”ì¶œ (ì•ì˜ ë‹¨ì–´ë§Œ)
            top_labels = [r["label"].split(",")[0].strip() for r in results[:5]]
            label_list = ", ".join(top_labels)

            prompt = (
                "You are an AI trained to write short, poetic image captions.\n"
                "Given the following image classification results, write one natural English sentence "
                "that gently describes what might be seen in the photo.\n\n"
                f"Labels: {label_list}\n\n"
                "Caption:"
            )



            # ê²°ê³¼ ì¶œë ¥
            response = client.text_generation(prompt=prompt, model="google/flan-t5-base", max_new_tokens=50)
            st.markdown("ğŸ“˜ **ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ê²°ê³¼**")
            st.write(response)

        except Exception as e:
            st.error(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
else:
    st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")




# # Hugging Face API ì„¤ì •
# API_URL = "https://api-inference.huggingface.co/models/facebook/bart-large-cnn"
# API_TOKEN = "" # Hugging Faceì—ì„œ ë°œê¸‰ë°›ì€ ê°œì¸ API í† í° ì…ë ¥
# headers = {
#     "Authorization": f"Bearer {API_TOKEN}"
# }
# # ìš”ì•½ ìš”ì²­ í•¨ìˆ˜
# def query(payload):
#     response = requests.post(API_URL, headers=headers, json=payload)
#     return response.json()
# # st.set_page_config(page_title="ì˜ë¬¸í…ìŠ¤íŠ¸ ìš”ì•½(API)")
# st.title("ì˜ë¬¸ í…ìŠ¤íŠ¸ ìš”ì•½(HF API)")
# text = st.text_area(" ìš”ì•½í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", height=200, placeholder="ê¸´ ë‰´ìŠ¤ ê¸°ì‚¬ë‚˜ ë¬¸ë‹¨ì„ ì…ë ¥í•´ë³´ì„¸ìš”...")
# if st.button("ìš”ì•½ ì‹œì‘"):
#     if len(text) < 30:
#         st.warning("ìµœì†Œ 30ì ì´ìƒ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
#     else:
#         with st.spinner("ìš”ì•½ ì¤‘..."):
#             output = query({
#                 "inputs": text,
#                 "parameters": {"max_length": 100, "min_length": 30, "do_sample": False}
#             })
#     try:
#         summary = output[0]["summary_text"]
#         st.success("ìš”ì•½ ì™„ë£Œ")
#         st.markdown(f"**ìš”ì•½ ê²°ê³¼:** {summary}")
#     except Exception as e:
#         st.error(f"ìš”ì•½ ì‹¤íŒ¨: {e}")