R^2(분류 :Accuracy,f1score 회귀: mse,rmse)

regression
분류 로지스틱
회귀 심플,멀티배리언트,랏쏘,릿지,폴리노미널

l1 regression
l2 regression

knn 
kval, distance가 결정 ,regression,classification

svm 
regression,classification
결정경계
서포트 벡터
커널 차원에 따라 리니어 폴리, rbf(가우시안)

트리 
regression,classification
decision tree
randomforest 
bagging(앙상블)
boosting(앙상블)
xgboost(트리계열의 정점 하이브리드 모델)
트리 여러개 모델을 쓰거나 다른 모델을 같이 쓰는걸 앙상블
스택킹:

물론입니다! 앞서 말씀드린 보완 사항들을 포함하여 머신러닝 모델 및 성능 지표를 **회귀/분류 중심**으로 전체적으로 깔끔하게 정리한 자료를 아래에 제공합니다. 발표자료나 필기 노트, 요약 자료로 활용하기 좋도록 **카테고리별**, **포인트 중심**으로 구성했습니다.

---

# ✅ 머신러닝 정리 요약 (회귀 · 분류 중심)

---

## 📊 성능 지표 (Metric)

### 1. 회귀(Regression)

| 지표                            | 설명                          |
| ----------------------------- | --------------------------- |
| **MSE (Mean Squared Error)**  | 오차 제곱 평균                    |
| **RMSE (Root MSE)**           | MSE의 제곱근, 해석 용이             |
| **MAE (Mean Absolute Error)** | 절댓값 오차 평균                   |
| **R² (결정계수)**                 | 모델이 데이터를 얼마나 잘 설명하는지 (0\~1) |

### 2. 분류(Classification)

| 지표            | 설명                            |
| ------------- | ----------------------------- |
| **Accuracy**  | 전체 중 정답 비율                    |
| **Precision** | 정답 중 예측이 맞은 비율                |
| **Recall**    | 실제 정답 중 맞춘 비율                 |
| **F1-score**  | Precision & Recall의 조화 평균     |
| **AUC-ROC**   | 분류 임계값 변화에 따른 성능 (이진 분류 시 유용) |

---

## 🧠 회귀 모델 (Regression Models)

| 모델                             | 설명                       |
| ------------------------------ | ------------------------ |
| **Simple Linear Regression**   | 독립변수 1개                  |
| **Multiple Linear Regression** | 독립변수 여러 개                |
| **Polynomial Regression**      | 다항식 관계 (비선형)             |
| **Lasso Regression (L1)**      | 가중치 일부를 0으로 만들어 변수 선택 효과 |
| **Ridge Regression (L2)**      | 가중치 크기를 작게 하여 과적합 방지     |
| **ElasticNet**                 | L1 + L2 혼합, 실무에서 자주 사용   |

---

## 🔎 분류 모델 (Classification Models)

### ✔️ 로지스틱 회귀

* **이진 분류**에 적합
* 시그모이드 함수 기반
* 출력값은 확률

### ✔️ K-최근접 이웃 (KNN)

* **회귀와 분류 모두 가능**
* 주요 파라미터:

  * `K 값`: 이웃 수
  * `거리 함수`: 유클리디안, 맨하탄 등
* 훈련은 빠르나 예측은 느릴 수 있음 (메모리 기반)

### ✔️ SVM (Support Vector Machine)

* **분류/회귀 모두 가능 (SVR은 회귀용)**
* 핵심 개념:

  * **결정 경계**: 마진 최대화
  * **서포트 벡터**: 경계를 정의하는 핵심 포인트
* 커널 종류:

  * **Linear**: 선형 경계
  * **Polynomial**: 다항식 경계
  * **RBF (Gaussian)**: 비선형 문제 대응 (가장 자주 사용)

---

## 🌲 트리 계열 모델 (Tree-Based)

| 모델                     | 설명                                       |
| ---------------------- | ---------------------------------------- |
| **Decision Tree**      | 분류/회귀 모두 가능, 과적합 주의                      |
| **Random Forest**      | 여러 트리를 배깅(Bagging)으로 조합, 안정적             |
| **Gradient Boosting**  | 이전 오차를 보완하며 순차적으로 학습                     |
| **XGBoost**            | Gradient Boosting + 성능 최적화, 가장 강력한 트리 모델 |
| **LightGBM, CatBoost** | 대규모 데이터에 적합한 최신 Boosting 모델들             |

---

## 🤖 앙상블 학습 (Ensemble Learning)

| 유형           | 설명                     | 예시                             |
| ------------ | ---------------------- | ------------------------------ |
| **Bagging**  | 여러 모델을 병렬로 학습          | Random Forest                  |
| **Boosting** | 약한 모델들을 순차적으로 학습       | XGBoost, AdaBoost              |
| **Stacking** | 서로 다른 모델을 조합 + 최종 메타모델 | SVM + RF → Logistic Regression |

---

## 🧩 스택킹 (Stacking) 핵심 요약

* 서로 다른 종류의 모델을 조합
* 개별 모델들의 예측값을 모아 **메타 모델**이 최종 예측
* 성능 향상 가능하지만, 과적합 및 복잡도 증가 주의

---

## 📘 요약 비교표

| 모델          | 회귀       | 분류 | 특징              |
| ----------- | -------- | -- | --------------- |
| 선형 회귀       | ✔️       | ❌  | 직선 모델, MSE 최소화  |
| 로지스틱 회귀     | ❌        | ✔️ | 확률 기반 이진 분류     |
| KNN         | ✔️       | ✔️ | 비매개변수 모델, 거리 기반 |
| SVM         | ✔️ (SVR) | ✔️ | 고차원, 커널 기법      |
| 트리          | ✔️       | ✔️ | 설명력 높음, 과적합 가능  |
| 랜덤 포레스트     | ✔️       | ✔️ | 배깅 기반 앙상블       |
| XGBoost     | ✔️       | ✔️ | 부스팅 기반, 고성능     |
| Lasso/Ridge | ✔️       | ❌  | 정규화 회귀, 과적합 방지  |

---

필요하시면 위 내용을 PDF나 슬라이드 형식으로 정리하거나, 각 알고리즘의 **Python 코드 예제**, 혹은 **모델 선택 가이드라인**도 함께 제공해 드릴 수 있습니다. 어떤 방식으로 더 발전시키고 싶으신가요?
