import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler, RobustScaler
from sklearn.metrics import r2_score, mean_squared_error
import streamlit as st

# ë°ì´í„°ì…‹ ë¡œë“œ
housing = fetch_california_housing(as_frame=True)
data = housing.frame
X = data.drop('MedHouseVal', axis=1)
y = data['MedHouseVal']

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Streamlit ì•± ì„¤ì •
st.title("California Housing Price Prediction")
st.write("This app trains regression models on the California Housing dataset and displays RÂ² score and RMSE.")

model_name = st.selectbox("Select Regression Model", ["Lasso", "Ridge", "Elastic Net", "Polynomial Regression"])

# ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ í•¨ìˆ˜
def get_scaler(scaler_name):
    if scaler_name == "StandardScaler":
        return StandardScaler()
    elif scaler_name == "MinMaxScaler":
        return MinMaxScaler()
    elif scaler_name == "RobustScaler":
        return RobustScaler()

# ê³µí†µ ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ
scaler_name = st.selectbox("Select a Scaler", ["StandardScaler", "MinMaxScaler", "RobustScaler"])
scaler = get_scaler(scaler_name)

# Polynomial Features ì²˜ë¦¬
if model_name == "Polynomial Regression":
    degree = st.slider("Select Polynomial Degree", min_value=1, max_value=5, value=2)
    poly = PolynomialFeatures(degree=degree, include_bias=False)
    X_train_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)
    X_train_scaled = scaler.fit_transform(X_train_poly)
    X_test_scaled = scaler.transform(X_test_poly)
else:
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

# ëª¨ë¸ ì„ íƒ ë° íŒŒë¼ë¯¸í„°
if model_name == "Lasso":
    alpha_lasso = st.slider("Select Lasso Alpha", 0.001, 10.0, 1.0, step=0.001)
    model = Lasso(alpha=alpha_lasso)
elif model_name == "Ridge":
    alpha_ridge = st.slider("Select Ridge Alpha", 0.001, 10.0, 1.0, step=0.001)
    model = Ridge(alpha=alpha_ridge)
elif model_name == "Elastic Net":
    alpha_elastic = st.slider("Select Elastic Net Alpha", 0.001, 10.0, 1.0, step=0.001)
    l1_ratio = st.slider("Select Elastic Net L1 Ratio", 0.1, 0.9, 0.5, step=0.1)
    model = ElasticNet(alpha=alpha_elastic, l1_ratio=l1_ratio)
elif model_name == "Polynomial Regression":
    model = LinearRegression()

# ëª¨ë¸ í•™ìŠµ
try:
    # ëª¨ë¸ í•™ìŠµ (ìŠ¤ì¼€ì¼ ì ìš©)
    model.fit(X_train_scaled, y_train)

    # ì˜ˆì¸¡
    y_pred = model.predict(X_test_scaled)


    # ì„±ëŠ¥ í‰ê°€
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    # ê²°ê³¼ ì¶œë ¥
    st.write(f"### {model_name} Results")
    if model_name == "Lasso":
        st.write(f"Alpha: {alpha_lasso}")
    elif model_name == "Ridge":
        st.write(f"Alpha: {alpha_ridge}")
    elif model_name == "Elastic Net":
        st.write(f"Alpha: {alpha_elastic}, L1 Ratio: {l1_ratio}")
    elif model_name == "Polynomial Regression":
        st.write(f"Degree: {degree}")

    st.write(f"RÂ² Score: {r2:.4f}")
    st.write(f"RMSE: {rmse:.4f}")

    col1, col2 = st.columns(2)

    with col1:
        st.write("### Actual vs Predicted Values")
        fig1, ax1 = plt.subplots(figsize=(6, 4))
        ax1.scatter(y_test, y_pred, color='blue', alpha=0.5)
        ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        ax1.set_xlabel('Actual Values')
        ax1.set_ylabel('Predicted Values')
        ax1.set_title(f'{model_name} - Actual vs Predicted')
        st.pyplot(fig1)

    with col2:
        st.write("### ì”ì°¨(residual) ë¶„í¬ ê·¸ë˜í”„")
        st.write("ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´(ì”ì°¨)ê°€ ì–´ë–»ê²Œ ë¶„í¬í•˜ëŠ”ì§€ ì‹œê°í™”í•˜ì—¬ ëª¨ë¸ì˜ í¸í–¥ ì—¬ë¶€ì™€ ì˜¤ì°¨ ë¶„í¬ë¥¼ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        residuals = y_test - y_pred
        fig2, ax2 = plt.subplots(figsize=(6, 4))
        ax2.hist(residuals, bins=30, edgecolor='black')
        ax2.set_title("Residuals Distribution")
        ax2.set_xlabel("Residual")
        ax2.set_ylabel("Frequency")
        st.pyplot(fig2)

    col3, col4 = st.columns(2)

    with col3:
        st.write("### Feature ì¤‘ìš”ë„ ì‹œê°í™”")
        st.write("ëª¨ë¸ì´ ì–´ë–¤ íŠ¹ì„±(feature)ì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í–ˆëŠ”ì§€ í™•ì¸í•¨ìœ¼ë¡œì¨ ëª¨ë¸ í•´ì„ë ¥ í–¥ìƒ.")
        if model_name in ["Lasso", "Ridge", "Elastic Net", "Polynomial Regression"]:
            fig3, ax3 = plt.subplots(figsize=(6, 4))
            coef = model.coef_
            feature_names = poly.get_feature_names_out(X.columns) if model_name == "Polynomial Regression" else X.columns
            ax3.barh(feature_names, coef)
            ax3.set_title("Feature Importance")
            st.pyplot(fig3)

    with col4:
        st.write("### ì˜ˆì¸¡ê°’ vs ì”ì°¨ ì‚°ì ë„ (Residual Plot)")
        st.write("ì˜ˆì¸¡ê°’ê³¼ ì”ì°¨ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì‹œê°í™”í•´ì„œ, ì”ì°¨ê°€ ë¬´ì‘ìœ„ë¡œ ë¶„í¬í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ëª¨ë¸ì´ ì‹œìŠ¤í…œì ìœ¼ë¡œ ì˜ëª»ëœ ì˜ˆì¸¡ì„ í•˜ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        fig4, ax4 = plt.subplots(figsize=(6, 4))
        ax4.scatter(y_pred, residuals, alpha=0.5)
        ax4.hlines(0, y_pred.min(), y_pred.max(), color='red')
        ax4.set_xlabel("Predicted Values")
        ax4.set_ylabel("Residuals")
        ax4.set_title("Residuals vs Predicted Values")
        st.pyplot(fig4)


except Exception as e:
    st.error(f"An error occurred: {str(e)}")


# ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”
if st.button("Compare All Models"):
    

    def evaluate_model(model, X_train, X_test, y_train, y_test):
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        return r2, rmse

    models = {
        "Lasso": Lasso(alpha=0.1),
        "Ridge": Ridge(alpha=1.0),
        "ElasticNet": ElasticNet(alpha=0.1, l1_ratio=0.5),
        "PolynomialRegression": LinearRegression()
    }

    results = []
    for name, model in models.items():
        if name == "PolynomialRegression":
            degree =1
            poly = PolynomialFeatures(degree=degree, include_bias=False)
            X_train_poly = poly.fit_transform(X_train)
            X_test_poly = poly.transform(X_test)
            X_train_scaled = scaler.fit_transform(X_train_poly)
            X_test_scaled = scaler.transform(X_test_poly)
        else:
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

        r2, rmse = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)
        results.append({"Model": name, "RÂ² Score": round(r2, 4), "RMSE": round(rmse, 4)})

    st.write("### ğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ")
    st.dataframe(pd.DataFrame(results))

# ë°ì´í„°ì…‹ ì •ë³´
st.write("### Dataset Info")
st.write(f"Features: {X.columns.tolist()}")
st.write(f"Number of Samples: {len(data)}")
st.write(f"Target: Median House Value (in $100,000s)")

# ì¬ì‹¤í–‰ ë²„íŠ¼
if st.button("Retrain Model"):
    st.rerun()
