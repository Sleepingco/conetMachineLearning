복습: 표준 정규 분포 큰수치의 데이터를 평균을 0으로 만들어서 수치를 단순하게 만들어서 계산에 용이하게 만듬
첨도와 왜도 정규분포가 평균에 맞지 않고 더 큰 구간이나 작은 구간에 분포되어있는 혹은 평균애 비해 수치가 큰경우
min-max x-xmin/(xmax-xmin) 으로 수치를 0~1범위로 변환
Softmax 주어진 입력 값을 확률분포로 변환(전체에 합이 1이 되게끔)
결측치에 대한 전처리 제거,대처
라벨 인코딩 범주가 정해저있는 데이터를 숫자(라벨)로 변환되며
원 핫 인코딩 범주가 정해져있는 해당 범주에만 1 나머지는 0
eda 데이터를 미리보고 다방면으로 이해하는 과정
상관분석 두변수간의 상관 관계(집값이 어디에 영향을 받냐 상권, 역세권, 교육환경 등등)를 분석하여 강도와 방향을 이해 두 변수 간의 강도와 방향을 나타내는 값(-1~ 1 사이) 0이되면 관계가 없다
결정계수 모델이 얼마나 잘설명하는지 측정
정사영 두 벡터가 같은 방향을 가리키게 했을때 크기를 비교할 수 있다.
전치 행렬 행과 열을 바꾼 것
미분 x 값이 작게 변할때 y값의 변화(기울기) 나중에는 기울기 값과 부호만 남을 정도로 작아지면 방향을 정한다?(이해가 안됨)
로스함수 모델이 3을 예측하면 실제값이 2일때 로스 함수는 1

경사하강법(딥러닝에서 가장중요)양수 일때는 숫자를 줄이고 기울기를 경사하강법에 미분하여 0에 가깝게 만드는게 목적 부호가 + 이므로 점점 수를 낮추면 미분한 값이 0에 가깝게 만드는게 목적
목적함수 모델을 만들면 오차를 줄이기 위해서는 수식화 해야지 기계한테 줄수있다 Mse
weight x 가 변할때 특정지점이 MinimumC Cost를 찾는게 목적
x좌표를 미분을 해봤더니 양수이고 기울기 값을 줄여가는 과정이 경사하강법
반대로 음수이면 숫자를 키우면서 0이 될때까지 기울기 값을 줄이는 방식
목적은 loss값이 최적이 되는 방법 경사하강법

연쇄 법칙 딥러닝에서 오차함수의 최적화를 위해 역전파를 시행할때 연쇄법칙에 의한 미분값(가중치)를 계산하게 된다. 합성함수 각 가중치를 조정하고 조정계수 알파값을 조정하여 원하는 결과에 도출하는게 딥러닝의 기초
경사하강법을 사용해 각 뉴런마다 미분값에 양수냐 음수냐에 따라 조정하게 된다

입력에서 출력 방향의 값을 순전파 거꾸로 올라가면 역전파(정확한건 아님 검사 필요)

k겹 교차 검증 100만개의 데이터를 받으면 한번에 학습시키는게 아니라 k개의 부분으로 나누고 각 부분을 한번씩 테스트세트로 사용하고 나머지를 훈련세트로 모델을 학습
k번의 학습의 평가를 통해 모델의 평균 성능을 계산

오버피팅 문제집 하나만 너무 풀어서 테스트에 통과 못한 경우
언더피팅 문제를 너무 안풀어서 테스트에 통과 못한 경우

이진분류 모델
2가지 경우 T/F를 맞춰야 하는 경우 평가법
모델이 양이라고 했는데 실제 양인경우 Precision 정밀도 FP를 줄이는 방향 ex)스팸매일
실제 True인데 모델이 얼마나 맞춘경우 Recall 재현율(민감도) FN을 줄이는 방향 ex) 암검출 테러,금융사기 심각성이 큰경우에 재현율이 높아야함
TP 금융사기가 있는 가입자를 금융사기범이라고 예측
FN 금융사기가 있는 가입자를 금융사기가 없다고 예측
TN 금융사기가 없는 가입자를 금융사기가 없다고 예측
FP 금융사기가 없는 가입자를 금융사기범이라고 예측
Accuracy 정확도

