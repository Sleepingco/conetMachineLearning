{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904bc94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "안녕! 오늘은 정말 화창한 봄날이네요. 조금 더워요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from playsound import playsound # 외부 스피커 재생\n",
    "from pathlib import Path\n",
    "import pygame\n",
    "import time\n",
    "\n",
    "# client.audio.transcriptions.create(\n",
    "#     file=..., # 필수: 오디오 파일 객체\n",
    "#     model=\"whisper-1\", # 필수: 모델 이름 (현재는 whisper-1 고정)\n",
    "#     prompt=..., # 선택: 힌트 문장 제공 (맥락 강화)\n",
    "#     response_format=..., # 선택: 응답 형식 (\"json\", \"text\", \"srt\", \"verbose_json\", \"vtt\")\n",
    "#     temperature=..., # 선택: 창의성/랜덤성 조절 (0.0~1.0)\n",
    "#     language=..., # 선택: 입력 음성의 언어 (예: \"en\", \"ko\", \"es\")\n",
    "#     timestamp_granularities=... # 선택: 세그먼트 정보 단위 설정 (베타)\n",
    "# )\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "audio_file = open(\"speech.mp3\", \"rb\")\n",
    "response = client.audio.transcriptions.create(\n",
    " file=audio_file,\n",
    " model=\"whisper-1\",\n",
    " response_format=\"text\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e3ba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 1 start: 0.0, end: 3.940000057220459,text: 안녕! 오늘은 정말 화창한 봄날이네요.\n"
     ]
    }
   ],
   "source": [
    "audio_file = open(\"speech.mp3\",\"rb\")\n",
    "transcription_json = client.audio.transcriptions.create(\n",
    "    file=audio_file,\n",
    "    model=\"whisper-1\",\n",
    "    response_format=\"verbose_json\"\n",
    ")\n",
    "\n",
    "first_segment = transcription_json.segments[0]\n",
    "print(f\"Segment 1 start: {first_segment.start}, end: {first_segment.end},text:{first_segment.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "fs = 16000 # 샘플레이트 16kHz\n",
    "seconds = 5 # 녹음 길이 (초)\n",
    "print(\"지금부터 5초간 녹음합니다...\")\n",
    "recording = sd.rec(int(seconds * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "sd.wait() # 녹음 완료 대기\n",
    "write(\"live_input.wav\", fs, recording) # WAV 파일로 저장\n",
    "# 저장한 녹음 파일을 Whisper API로 전송\n",
    "with open(\"live_input.wav\", \"rb\") as audio_file:\n",
    " live_transcript = client.audio.transcriptions.create(\n",
    " file=audio_file,\n",
    " model=\"whisper-1\",\n",
    " response_format=\"text\",\n",
    " language=\"ko\" # 예: 한국어로 가정하고 명시 (자동감지도 가능)\n",
    " )\n",
    "print(\"실시간 녹음 변환 결과:\", live_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc55e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import time\n",
    "# OpenAI API 클라이언트\n",
    "client = OpenAI()\n",
    "# 기본 설정\n",
    "fs = 16000 # 샘플레이트 (16kHz)\n",
    "seconds = 5 # 녹음 시간 (초)\n",
    "filename = \"live_input.wav\"\n",
    "# 1. 녹음 시작\n",
    "print(\" 지금부터 5초간 녹음합니다...\")\n",
    "recording = sd.rec(int(seconds * fs), samplerate=fs, channels=1, dtype='int16')\n",
    "sd.wait()\n",
    "write(filename, fs, recording)\n",
    "print(\" 녹음 완료!\")\n",
    "# 2. Whisper로 한국어 텍스트 변환\n",
    "with open(filename, \"rb\") as audio_file:\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "    file=audio_file,\n",
    "    model=\"whisper-1\",\n",
    "    response_format=\"text\",\n",
    "    language=\"ko\"\n",
    " )\n",
    "print(\"인식된 텍스트:\", transcript)\n",
    "print(\"\\n [인식된 자막 - 한국어]\")\n",
    "print(transcript)\n",
    "# 3. GPT로 영어 번역\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Translate the following Korean sentence into natural English.\"},\n",
    "    {\"role\": \"user\", \"content\": transcript}\n",
    "]\n",
    "translation_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # 또는 \"gpt-3.5-turbo\"\n",
    "    messages=messages,\n",
    "    temperature=0.3\n",
    ")\n",
    "english_translation = translation_response.choices[0].message.content\n",
    "print(\"\\n [자동 번역 - 영어]\")\n",
    "print(english_translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_api_part1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
