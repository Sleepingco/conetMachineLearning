# -*- coding: utf-8 -*-
"""ML0508.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rWNAU2NtzSfrKLiKcj73UcdWcYnrnBSv
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

# 데이터 생성
data = {'Age':[25,30,None,24,29],'Salary':[50000,54000,58000,None,62000],'Category':['A','B','A','B','C']}
df = pd.DataFrame(data)
print(df)

# 결측치 처리
df['Age'].fillna(df['Age'].mean(),inplace=True)
df.dropna(subset=['Salary'],inplace=True)
print(df)

# 데이터 정규화
scaler = MinMaxScaler()
df[['Age','Salary']] = scaler.fit_transform(df[['Age','Salary']])
print(df)

# 표준화
scaler = StandardScaler()
df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])
print(df)

# 특성 공학
df['Age_Salary_Ratio'] = df['Age']/df['Salary']
print(df)

# 차원 축소
pca = PCA(n_components=2)
reduced_data=pca.fit_transform(df[['Age','Salary']])
print(df)

# 라벨 인코딩
encoder = LabelEncoder()
df['Category'] = encoder.fit_transform(df['Category'])
print(df)

# 원-핫 인코딩
df = pd.get_dummies(df,columns=['Category'])
print(df)

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(df[['Age', 'Salary']], df['Age_Salary_Ratio'], test_size=0.2, random_state=42)

print(df)
print("Reduced data:", reduced_data)
print("Train set:", X_train, y_train)
print("Test set:", X_test, y_test)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 데이터 생성
data =  {"Age":[25,30,24,29,40,50,35],'Salary':[50000,54000,58000,62000,70000,80000,65000]}
df = pd.DataFrame(data)
print(df)

# 기술 통계량
print("기술통계랑:\n",df.describe())

# 히스토그램
sns.histplot(df['Age'])
plt.title('Age Distribution')
plt.show()

# 박스플롯
sns.boxplot(x=df['Age'])
plt.title('Age Box Plot')
plt.show()

# 산점도
sns.scatterplot(x='Age',y='Salary',data=df)
plt.title('Age vs Salary Scatter plot')
plt.show()

# 상관 분석
correlation = df.corr()
print("상관계수\n",correlation)
sns.heatmap(correlation,annot=True,cmap="coolwarm")
plt.title('Correlation Heatmap')
plt.show()

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

# 1. 데이터 생성
# 나이, 연봉, 부서, 구매여부를 포함한 가상의 고객 데이터 생성
# 실제 모델 학습에 사용할 데이터프레임(df)을 만듦
data = {
    'Age': [25, 30, 45, np.nan, 35, 50, 23],
    'Salary': [50000, 60000, 80000, 75000, np.nan, 120000, 45000],
    'Department': ['HR', 'Engineering', 'HR', 'Marketing', 'Engineering', 'HR', 'Marketing'],
    'Purchased': ['Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No']
}
df = pd.DataFrame(data)

# 2. 결측치 처리
# NaN 값을 평균/중앙값으로 채워 결측치를 제거
# → 대부분의 머신러닝 알고리즘은 결측치를 처리하지 못하므로 반드시 전처리가 필요함
df['Age'].fillna(df['Age'].mean(), inplace=True)
df['Salary'].fillna(df['Salary'].median(), inplace=True)

# 3. 정규화 (Min-Max Scaling)
# Age와 Salary를 0~1 범위로 변환
# → 서로 다른 스케일을 가진 수치형 데이터를 동일한 기준으로 맞춰줌
scaler = MinMaxScaler()
df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])

# 4. 특성 공학
# 나이에 대한 연봉 비율(Salary_per_Age)이라는 파생 변수 생성
# → 기존 데이터를 조합해 의미 있는 새로운 정보를 추출함으로써 모델의 성능을 높임
df['Salary_per_Age'] = df['Salary'] / (df['Age'] + 1e-6)  # 0으로 나누는 오류 방지용 소수 추가

# 5. 라벨 인코딩
# 문자열인 Purchased(Yes/No)를 숫자(1/0)로 변환
# → 대부분의 머신러닝 모델은 문자열을 처리하지 못하므로 숫자형 변환이 필요함
le = LabelEncoder()
df['Purchased_Label'] = le.fit_transform(df['Purchased'])

# 6. 원-핫 인코딩
# 범주형 변수인 Department를 각 부서별 이진 열로 변환
# → 범주형 변수에 숫자를 직접 할당하면 순서 의미가 생겨버려 부작용이 발생할 수 있음. 이를 방지하기 위해 One-Hot 방식 사용
df = pd.get_dummies(df, columns=['Department'])

# 7. 표준화 (Z-score Scaling)
# Age, Salary, Salary_per_Age를 평균 0, 표준편차 1로 변환
# → 정규화와 달리 음수도 포함되며, 회귀나 거리 기반 모델에 특히 유리함
std_scaler = StandardScaler()
df[['Age', 'Salary', 'Salary_per_Age']] = std_scaler.fit_transform(df[['Age', 'Salary', 'Salary_per_Age']])

# 8. 차원 축소 (PCA)
# 3개의 수치형 특성을 2개의 주성분으로 압축
# → 계산 비용 감소, 과적합 방지, 시각화 등에 유리하며, 유사한 정보를 요약함
pca = PCA(n_components=2)
pca_features = pca.fit_transform(df[['Age', 'Salary', 'Salary_per_Age']])
df[['PC1', 'PC2']] = pca_features  # 축소된 차원을 새로운 열로 추가

# 9. 데이터 분할
# 전체 데이터를 학습용(X_train)과 평가용(X_test)으로 분리
# → 모델이 새로운 데이터에 얼마나 잘 일반화되는지를 확인하기 위해 필수적인 과정
X = df[['PC1', 'PC2'] + [col for col in df.columns if col.startswith('Department_')]]  # 입력 특성
y = df['Purchased_Label']  # 예측할 목표값

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 최종 출력: 학습 데이터와 라벨 확인
print("학습 데이터:")
print(X_train)

print("\n라벨:")
print(y_train)

import numpy as up
import pandas as pd

# 데이터 생성
data = {
'Height': [160, 165, 170, 175, 180],
'Weight': [60, 65, 70, 75, 80]
}

df = pd.DataFrame(data)

# 상관계수 계산
correlation_matrix = np.corrcoef(df['Height'], df['Weight'])
correlation = correlation_matrix[0, 1]

print("상관계수:", correlation)

#공선성 계산 (VIF)
from statsmodels.stats.outliers_influence import variance_inflation_factor
X = df [['Height', 'Weight']]
vif = pd.DataFrame()
vif ["Features"] = X.columns
vif["VIF"] = [variance_inflation_factor (X.values, i) for i in range(X.shape [1])]
print("공선성 (VIF):")
print(vif)