Regression, knn/svm, dt/ensemble/xgboost,unsupervised learning
통계는 표본에서 모집단 추론을 끌어내고 기계 학습은 일반화 가능한 예측 패턴을 찾는다
기계학습- 지도학습(분류,회귀),비지도학습(클러스터링),강화학습
scikit-learn algorithm cheat-sheet
다변수미적분,알고리즘,확률과통계,선형대수

아래는 인공지능과 머신러닝의 핵심 용어 50개에 대한 간단한 설명입니다. 5개 주제별로 구분하여 깔끔하게 정리해드렸습니다.

---

## 1. 기본 개념 (기초를 튼튼히)

1. **데이터셋 (Dataset)**: 학습이나 평가에 사용되는 데이터 모음.
2. **피처 (Feature)**: 데이터의 속성이나 입력 값.
3. **레이블 (Label)**: 데이터에 대한 정답 또는 출력 값.
4. **정답 (Ground Truth)**: 실제 참값으로, 모델의 예측과 비교 기준이 됨.
5. **모델 (Model)**: 입력 데이터를 처리하여 예측을 수행하는 수학적 구조.
6. **학습 (Training)**: 모델이 데이터에서 규칙을 찾아가는 과정.
7. **추론 (Inference / Prediction)**: 학습된 모델로 새로운 데이터에 대해 예측하는 것.
8. **정확도 (Accuracy)**: 전체 중 맞춘 예측의 비율.
9. **손실 함수 (Loss Function)**: 예측과 정답의 차이를 수치로 표현한 함수.
10. **최적화 (Optimization)**: 손실 값을 최소화하기 위해 파라미터를 조정하는 과정.

---

## 2. 알고리즘 및 기법

11. **회귀 (Regression)**: 연속적인 값을 예측하는 문제.
12. **분류 (Classification)**: 데이터를 범주나 클래스로 나누는 문제.
13. **클러스터링 (Clustering)**: 비슷한 데이터끼리 그룹으로 묶는 작업 (비지도학습).
14. **지도학습 (Supervised Learning)**: 정답이 주어진 데이터를 이용한 학습.
15. **비지도학습 (Unsupervised Learning)**: 정답 없이 데이터의 구조를 찾는 학습.
16. **강화학습 (Reinforcement Learning)**: 보상을 최대화하는 행동을 학습하는 방식.
17. **최근접 이웃 (KNN)**: 가까운 데이터 포인트를 기준으로 예측.
18. **결정트리 (Decision Tree)**: 조건을 기준으로 분기하며 예측하는 모델.
19. **랜덤 포레스트 (Random Forest)**: 여러 결정트리를 조합한 앙상블 모델.
20. **서포트 벡터 머신 (SVM)**: 데이터를 구분하는 최적의 경계선을 찾는 알고리즘.

---

## 3. 딥러닝 기초

21. **신경망 (Neural Network)**: 뇌의 뉴런을 모방한 계층 구조 모델.
22. **퍼셉트론 (Perceptron)**: 가장 단순한 형태의 인공 뉴런 모델.
23. **다층 퍼셉트론 (MLP)**: 여러 은닉층을 가진 기본적인 신경망 구조.
24. **은닉층 (Hidden Layer)**: 입력과 출력 사이의 중간 계층.
25. **활성화 함수 (Activation Function)**: 뉴런의 출력을 결정하는 함수.
26. **ReLU / Sigmoid / Tanh**: 대표적인 활성화 함수 종류.
27. **경사 하강법 (Gradient Descent)**: 손실을 줄이기 위한 파라미터 조정 방법.
28. **오차 역전파 (Backpropagation)**: 오차를 뒤로 전파하여 가중치를 업데이트하는 기법.
29. **에폭 (Epoch)**: 전체 데이터를 한 번 모두 학습하는 횟수.
30. **배치 사이즈 (Batch Size)**: 한 번에 학습에 사용하는 데이터 개수.

---

## 4. 성능 및 과적합 관련 용어

31. **과적합 (Overfitting)**: 학습 데이터에는 잘 맞지만 새로운 데이터에 성능이 떨어짐.
32. **과소적합 (Underfitting)**: 데이터의 패턴을 제대로 학습하지 못한 상태.
33. **정규화 (Regularization)**: 과적합을 방지하기 위한 제약을 추가하는 기법.
34. **드롭아웃 (Dropout)**: 일부 뉴런을 임의로 꺼서 일반화 성능을 높이는 기법.
35. **교차검증 (Cross Validation)**: 데이터를 나눠가며 여러 번 학습/검증하는 방법.
36. **검증셋 (Validation Set)**: 학습 중 모델 성능을 평가하기 위한 데이터.
37. **테스트셋 (Test Set)**: 최종적으로 모델의 성능을 평가하는 데이터.
38. **바이어스 (Bias)**: 예측이 정답과 얼마나 벗어나는지를 나타내는 오류의 한 종류.
39. **분산 (Variance)**: 데이터마다 예측이 얼마나 들쭉날쭉한지를 나타냄.
40. **하이퍼파라미터 (Hyperparameter)**: 학습 전 사람이 설정하는 값 (예: 학습률, 배치 크기 등).

---

## 5. 실전 및 활용 관련 용어

41. **파라미터 튜닝 (Parameter Tuning)**: 모델 성능 향상을 위한 설정값 조정.
42. **전이 학습 (Transfer Learning)**: 학습된 모델을 다른 문제에 적용하는 기법.
43. **파인튜닝 (Fine-tuning)**: 전이 학습 후 기존 모델 일부를 다시 학습시키는 과정.
44. **피처 스케일링 (Feature Scaling)**: 서로 다른 범위의 데이터를 비슷한 수준으로 조정.
45. **표준화/정규화 (Standardization / Normalization)**: 데이터 분포를 일정하게 조정.
46. **차원 축소 (Dimensionality Reduction)**: 중요한 정보를 남기고 불필요한 특성을 줄이는 과정.
47. **PCA (주성분 분석)**: 데이터를 가장 잘 설명하는 축으로 변환하는 대표적 차원 축소 기법.
48. **t-SNE (고차원 시각화 기법)**: 고차원 데이터를 2D나 3D로 시각화하는 기술.
49. **혼동 행렬 (Confusion Matrix)**: 예측 결과와 실제 결과를 비교하는 행렬.
50. **ROC 곡선 / AUC**: 이진 분류 모델의 성능을 평가하는 곡선과 면적 지표.

---

## 🔍 기초 수학·통계 기반 개념

* **확률분포 (Probability Distribution)**: 정규분포, 베르누이분포, 이항분포 등.
* **베이즈 정리 (Bayes' Theorem)**: 조건부 확률 기반 예측.
* **MLE / MAP**: 최대우도추정(Maximum Likelihood Estimation), 최대사후확률(Maximum a Posteriori).
* **편향-분산 트레이드오프 (Bias-Variance Tradeoff)**: 모델 성능의 균형 이슈.

---

## 🧠 신경망 구조 관련

* **CNN (Convolutional Neural Network)**: 이미지 처리에 특화된 구조.
* **RNN (Recurrent Neural Network)**: 시퀀스 데이터(문장, 시계열)에 적합한 구조.
* **LSTM / GRU**: 장기 의존성(long-term dependency)을 해결한 순환 구조.
* **Transformer**: 현재 대부분의 자연어 처리에서 사용하는 구조. (ex: BERT, GPT 등)
* **Attention**: 입력 간의 중요도 관계를 반영하는 메커니즘.

---

## 🔧 학습 기술 및 최적화 전략

* **Learning Rate Decay**: 학습률을 점진적으로 줄이는 방법.
* **Momentum / Adam / RMSprop**: 다양한 최적화 알고리즘.
* **Early Stopping**: 과적합을 방지하기 위해 학습을 중단하는 기법.
* **Gradient Clipping**: 폭주하는 그래디언트를 잘라내는 방법.

---

## 🧪 실전 모델 평가/검증

* **Precision / Recall / F1-score**: 분류 문제에서 중요한 세부 평가 지표.
* **Log Loss / Cross Entropy**: 분류에서 주로 사용하는 손실 함수.
* **Top-k Accuracy**: 예측 순위 안에 정답이 포함됐는지를 평가.
* **BLEU / ROUGE / METEOR**: 자연어 생성 모델(NLP) 평가 지표.

---

## 🧭 실무 환경 / MLOps 관련

* **파이프라인 (Pipeline)**: 전처리부터 예측까지 과정을 체계적으로 구성.
* **모델 서빙 (Model Serving)**: 학습한 모델을 실제 서비스에 배포하는 기술.
* **ONNX / TorchScript / TensorRT**: 모델 최적화 및 호환 기술.
* **데이터 드리프트**: 운영 중 데이터 분포가 바뀌는 문제.

---

## 💡 학습 관련 고급 개념

* **Self-Supervised Learning**: 일부만 라벨이 있는 상황에서 학습하는 방식.
* **Contrastive Learning**: 비슷한/다른 데이터쌍을 학습에 활용.
* **Knowledge Distillation**: 큰 모델 지식을 작은 모델에 전달.

---

## 🤖 AI 활용 트렌드 및 구조

* **BERT / GPT / T5**: 대표적인 사전학습 기반 언어모델.
* **Diffusion Model**: 이미지 생성에 사용하는 최신 딥러닝 모델.
* **Generative AI / LLM**: 생성형 인공지능, 대형 언어 모델.

---